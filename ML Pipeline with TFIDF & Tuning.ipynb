{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and load data from database\n",
    "- Import python libraries\n",
    "- Load dataset from database with read_sql_table\n",
    "- Define feature and target variables X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load engine from database \n",
    "engine = create_engine('sqlite:///data/DisasterResponse.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('DisasterResponse1.sql',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.drop(['id','message','original','genre'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a tokenization function to process your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nirzaree/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nirzaree/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nirzaree/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the text processing steps and then write a function for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = X[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather update - a cold front from cuba that could pass over haiti'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather update   a cold front from cuba that could pass over haiti'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.sub(r'[^A-Za-z0-9]',' ',text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'from',\n",
       " 'cuba',\n",
       " 'that',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'over',\n",
       " 'haiti']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pass', 'haiti']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [x for x in text if x not in stop_words]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_tok = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in text: \n",
    "    lem_tok.append(lemmatizer.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^A-Za-z0-9]',' ',text)\n",
    "    text = word_tokenize(text)\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_tokens = []\n",
    "    for token in text:\n",
    "        lem_tokens.append(lemmatizer.lemmatize(token))\n",
    "    return lem_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = [\"I like India\",\"India is my homeland\",\"I have travelled to Asia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = [tokenize(x) for x in test_tfidf] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.60534851, 0.79596054, 0.        ],\n",
       "       [0.        , 0.79596054, 0.60534851, 0.        , 0.        ],\n",
       "       [0.70710678, 0.        , 0.        , 0.        , 0.70710678]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(test_tfidf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "[\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    ('rf_multi', MultiOutputClassifier(RandomForestClassifier()))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   TfidfVectorizer(tokenizer=<function tokenize at 0x7f96e61cfee0>)),\n",
       "  ('rf_multi', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'verbose': False,\n",
       " 'vect': TfidfVectorizer(tokenizer=<function tokenize at 0x7f96e61cfee0>),\n",
       " 'rf_multi': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.float64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__norm': 'l2',\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__smooth_idf': True,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__sublinear_tf': False,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__use_idf': True,\n",
       " 'vect__vocabulary': None,\n",
       " 'rf_multi__estimator__bootstrap': True,\n",
       " 'rf_multi__estimator__ccp_alpha': 0.0,\n",
       " 'rf_multi__estimator__class_weight': None,\n",
       " 'rf_multi__estimator__criterion': 'gini',\n",
       " 'rf_multi__estimator__max_depth': None,\n",
       " 'rf_multi__estimator__max_features': 'auto',\n",
       " 'rf_multi__estimator__max_leaf_nodes': None,\n",
       " 'rf_multi__estimator__max_samples': None,\n",
       " 'rf_multi__estimator__min_impurity_decrease': 0.0,\n",
       " 'rf_multi__estimator__min_impurity_split': None,\n",
       " 'rf_multi__estimator__min_samples_leaf': 1,\n",
       " 'rf_multi__estimator__min_samples_split': 2,\n",
       " 'rf_multi__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'rf_multi__estimator__n_estimators': 100,\n",
       " 'rf_multi__estimator__n_jobs': None,\n",
       " 'rf_multi__estimator__oob_score': False,\n",
       " 'rf_multi__estimator__random_state': None,\n",
       " 'rf_multi__estimator__verbose': 0,\n",
       " 'rf_multi__estimator__warm_start': False,\n",
       " 'rf_multi__estimator': RandomForestClassifier(),\n",
       " 'rf_multi__n_jobs': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = GridSearchCV(pipeline,\n",
    "             param_grid={'rf_multi__estimator__n_estimators': [50,100]},\n",
    "             cv=2,\n",
    "             n_jobs=1,\n",
    "             verbose=3\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] rf_multi__estimator__n_estimators=50 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf_multi__estimator__n_estimators=50, score=0.258, total= 1.4min\n",
      "[CV] rf_multi__estimator__n_estimators=50 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf_multi__estimator__n_estimators=50, score=0.257, total= 1.5min\n",
      "[CV] rf_multi__estimator__n_estimators=100 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf_multi__estimator__n_estimators=100, score=0.261, total= 2.7min\n",
      "[CV] rf_multi__estimator__n_estimators=100 ...........................\n",
      "[CV]  rf_multi__estimator__n_estimators=100, score=0.257, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(tokenizer=<function tokenize at 0x7f96e61cfee0>)),\n",
       "                                       ('rf_multi',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=1,\n",
       "             param_grid={'rf_multi__estimator__n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13763</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21716</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "13763        1        0      0            0             0                 0   \n",
       "21716        1        0      1            1             0                 1   \n",
       "16002        1        0      0            0             0                 0   \n",
       "3745         1        0      0            1             0                 0   \n",
       "12096        1        0      0            1             0                 0   \n",
       "\n",
       "       search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "13763                  0         0         0            0  ...            0   \n",
       "21716                  0         0         0            0  ...            0   \n",
       "16002                  0         0         0            0  ...            0   \n",
       "3745                   0         0         0            0  ...            0   \n",
       "12096                  0         0         0            0  ...            0   \n",
       "\n",
       "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "13763                     0                1       0      1     0           0   \n",
       "21716                     0                0       0      0     0           0   \n",
       "16002                     0                0       0      0     0           0   \n",
       "3745                      0                0       0      0     0           0   \n",
       "12096                     1                1       1      0     0           0   \n",
       "\n",
       "       cold  other_weather  direct_report  \n",
       "13763     0              1              0  \n",
       "21716     0              0              0  \n",
       "16002     0              0              0  \n",
       "3745      0              0              1  \n",
       "12096     0              0              1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.40      0.51      1509\n",
      "           1       0.84      0.95      0.89      5004\n",
      "           2       0.50      0.49      0.49        41\n",
      "\n",
      "    accuracy                           0.82      6554\n",
      "   macro avg       0.68      0.61      0.63      6554\n",
      "weighted avg       0.80      0.82      0.80      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.iloc[:,0],y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6473\n",
       "1      81\n",
       "Name: missing_people, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[:,15].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Column =  related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.40      0.51      1509\n",
      "           1       0.84      0.95      0.89      5004\n",
      "           2       0.50      0.49      0.49        41\n",
      "\n",
      "    accuracy                           0.82      6554\n",
      "   macro avg       0.68      0.61      0.63      6554\n",
      "weighted avg       0.80      0.82      0.80      6554\n",
      "\n",
      "Target Column =  request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5419\n",
      "           1       0.83      0.49      0.61      1135\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.87      0.73      0.78      6554\n",
      "weighted avg       0.89      0.89      0.88      6554\n",
      "\n",
      "Target Column =  offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6531\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "Target Column =  aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      3812\n",
      "           1       0.76      0.68      0.72      2742\n",
      "\n",
      "    accuracy                           0.78      6554\n",
      "   macro avg       0.77      0.76      0.77      6554\n",
      "weighted avg       0.78      0.78      0.78      6554\n",
      "\n",
      "Target Column =  medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      6030\n",
      "           1       0.55      0.05      0.09       524\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.74      0.52      0.53      6554\n",
      "weighted avg       0.89      0.92      0.89      6554\n",
      "\n",
      "Target Column =  medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6227\n",
      "           1       0.81      0.09      0.16       327\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.88      0.55      0.57      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Target Column =  search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6364\n",
      "           1       0.60      0.03      0.06       190\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.79      0.52      0.52      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "Target Column =  security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6445\n",
      "           1       0.00      0.00      0.00       109\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.97      0.98      0.98      6554\n",
      "\n",
      "Target Column =  military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6355\n",
      "           1       0.88      0.11      0.19       199\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.92      0.55      0.59      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      "\n",
      "Target Column =  child_alone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirzaree/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "Target Column =  water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6130\n",
      "           1       0.87      0.33      0.48       424\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.91      0.66      0.73      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Target Column =  food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      5827\n",
      "           1       0.86      0.65      0.74       727\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.91      0.82      0.86      6554\n",
      "weighted avg       0.95      0.95      0.95      6554\n",
      "\n",
      "Target Column =  shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5966\n",
      "           1       0.84      0.38      0.53       588\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.89      0.69      0.75      6554\n",
      "weighted avg       0.93      0.94      0.93      6554\n",
      "\n",
      "Target Column =  clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6445\n",
      "           1       0.82      0.08      0.15       109\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.90      0.54      0.57      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      "\n",
      "Target Column =  money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6418\n",
      "           1       1.00      0.04      0.07       136\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.52      0.53      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Target Column =  missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6473\n",
      "           1       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Target Column =  refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6341\n",
      "           1       0.40      0.01      0.02       213\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.68      0.50      0.50      6554\n",
      "weighted avg       0.95      0.97      0.95      6554\n",
      "\n",
      "Target Column =  death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6252\n",
      "           1       0.90      0.18      0.29       302\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.93      0.59      0.64      6554\n",
      "weighted avg       0.96      0.96      0.95      6554\n",
      "\n",
      "Target Column =  other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5687\n",
      "           1       0.67      0.03      0.06       867\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.77      0.51      0.50      6554\n",
      "weighted avg       0.84      0.87      0.82      6554\n",
      "\n",
      "Target Column =  infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6097\n",
      "           1       0.00      0.00      0.00       457\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.47      0.50      0.48      6554\n",
      "weighted avg       0.87      0.93      0.90      6554\n",
      "\n",
      "Target Column =  transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6241\n",
      "           1       0.96      0.08      0.14       313\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.96      0.54      0.56      6554\n",
      "weighted avg       0.96      0.96      0.94      6554\n",
      "\n",
      "Target Column =  buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6232\n",
      "           1       0.74      0.12      0.21       322\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.85      0.56      0.59      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Target Column =  electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6416\n",
      "           1       0.50      0.02      0.04       138\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.74      0.51      0.52      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "Target Column =  tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6507\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Target Column =  hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6474\n",
      "           1       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Target Column =  shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6522\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "Target Column =  aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6477\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Target Column =  other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6235\n",
      "           1       0.00      0.00      0.00       319\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.91      0.95      0.93      6554\n",
      "\n",
      "Target Column =  weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      4688\n",
      "           1       0.86      0.70      0.77      1866\n",
      "\n",
      "    accuracy                           0.88      6554\n",
      "   macro avg       0.87      0.83      0.84      6554\n",
      "weighted avg       0.88      0.88      0.88      6554\n",
      "\n",
      "Target Column =  floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      5997\n",
      "           1       0.92      0.44      0.59       557\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.94      0.72      0.78      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Target Column =  storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      5887\n",
      "           1       0.79      0.52      0.63       667\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.87      0.75      0.80      6554\n",
      "weighted avg       0.93      0.94      0.93      6554\n",
      "\n",
      "Target Column =  fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6489\n",
      "           1       1.00      0.02      0.03        65\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       1.00      0.51      0.51      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Target Column =  earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5962\n",
      "           1       0.89      0.79      0.84       592\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.94      0.89      0.91      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "Target Column =  cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6431\n",
      "           1       0.73      0.09      0.16       123\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.86      0.54      0.58      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      "\n",
      "Target Column =  other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6190\n",
      "           1       0.55      0.03      0.06       364\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.75      0.52      0.52      6554\n",
      "weighted avg       0.92      0.94      0.92      6554\n",
      "\n",
      "Target Column =  direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91      5263\n",
      "           1       0.78      0.35      0.49      1291\n",
      "\n",
      "    accuracy                           0.85      6554\n",
      "   macro avg       0.82      0.66      0.70      6554\n",
      "weighted avg       0.84      0.85      0.83      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for colno in range(y_test.shape[1]):\n",
    "    print(\"Target Column = \", y_test.columns[colno])\n",
    "    print(classification_report(y_test.iloc[:,colno],y_pred[:,colno]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for a new input\n",
    "test_input = [\"I have not had anything to eat in the last 2 days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = CV.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [int(x) for interim in test_pred for x in interim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'related': 1,\n",
       " 'request': 0,\n",
       " 'offer': 0,\n",
       " 'aid_related': 0,\n",
       " 'medical_help': 0,\n",
       " 'medical_products': 0,\n",
       " 'search_and_rescue': 0,\n",
       " 'security': 0,\n",
       " 'military': 0,\n",
       " 'child_alone': 0,\n",
       " 'water': 0,\n",
       " 'food': 0,\n",
       " 'shelter': 0,\n",
       " 'clothing': 0,\n",
       " 'money': 0,\n",
       " 'missing_people': 0,\n",
       " 'refugees': 0,\n",
       " 'death': 0,\n",
       " 'other_aid': 0,\n",
       " 'infrastructure_related': 0,\n",
       " 'transport': 0,\n",
       " 'buildings': 0,\n",
       " 'electricity': 0,\n",
       " 'tools': 0,\n",
       " 'hospitals': 0,\n",
       " 'shops': 0,\n",
       " 'aid_centers': 0,\n",
       " 'other_infrastructure': 0,\n",
       " 'weather_related': 0,\n",
       " 'floods': 0,\n",
       " 'storm': 0,\n",
       " 'fire': 0,\n",
       " 'earthquake': 0,\n",
       " 'cold': 0,\n",
       " 'other_weather': 0,\n",
       " 'direct_report': 0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(y_train.columns,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_inp = X_train[ y_train['electricity'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The storm destroyed 275,000 acres (111,288 hectares) of farmland, breached 600 irrigation canals, swept away hundreds of bridges and roads and snapped electricity supplies across wide swathes of the state.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec_inp.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = '../models/classifier.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_filepath, 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
